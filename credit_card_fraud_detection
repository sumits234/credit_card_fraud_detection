import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from imblearn.over_sampling import SMOTE
import joblib

# Loading the dataset
data = pd.read_csv('/content/drive/MyDrive/creditcard_for_fraud_detection.csv')

# Preprocessing of  data
data['Amount'] = StandardScaler().fit_transform(data[['Amount']])
data = data.drop(['Time'], axis=1)
data = data.drop_duplicates()

# Split data into features and target
x = data.drop('Class', axis=1)
y = data['Class']

# 1. **Undersampling**
fraud = data[data['Class'] == 1]
normal = data[data['Class'] == 0]
normal_sample = normal.sample(n=len(fraud), random_state=42)  # Downsampling normal class to match fraud class
undersampled_data = pd.concat([normal_sample, fraud], ignore_index=True)
X_undersample = undersampled_data.drop('Class', axis=1)
y_undersample = undersampled_data['Class']

# Train-test split for undersampled data
x_train_under, x_test_under, y_train_under, y_test_under = train_test_split(X_undersample, y_undersample, test_size=0.2, random_state=42)

# 2. **Oversampling with SMOTE**
x_res, y_res = SMOTE(random_state=42).fit_resample(x, y)

# Train-test split for oversampled data
x_train_res, x_test_res, y_train_res, y_test_res = train_test_split(x_res, y_res, test_size=0.2, random_state=42)

# Classification with Logistic Regression and Decision Tree for both undersampling and oversampling
print("\n====== UNDERSAMPLING ======")
classifiers = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree Classifier": DecisionTreeClassifier()
}

for name, clf in classifiers.items():
    print(f"\n========== {name} (Undersampling) ===========")
    clf.fit(x_train_under, y_train_under)
    y_pred_under = clf.predict(x_test_under)
    print(f"Accuracy: {accuracy_score(y_test_under, y_pred_under)}")
    print(f"ROC AUC Score: {roc_auc_score(y_test_under, y_pred_under)}")
    print(f"Precision: {precision_score(y_test_under, y_pred_under)}")
    print(f"Recall: {recall_score(y_test_under, y_pred_under)}")
    print(f"F1 Score: {f1_score(y_test_under, y_pred_under)}")

print("\n====== OVERSAMPLING ======")
for name, clf in classifiers.items():
    print(f"\n========== {name} (Oversampling) ===========")
    clf.fit(x_train_res, y_train_res)
    y_pred_res = clf.predict(x_test_res)
    print(f"Accuracy: {accuracy_score(y_test_res, y_pred_res)}")
    print(f"ROC AUC Score: {roc_auc_score(y_test_res, y_pred_res)}")
    print(f"Precision: {precision_score(y_test_res, y_pred_res)}")
    print(f"Recall: {recall_score(y_test_res, y_pred_res)}")
    print(f"F1 Score: {f1_score(y_test_res, y_pred_res)}")

# Train Decision Tree Classifier on oversampled data
dtc = DecisionTreeClassifier()
dtc.fit(x_res, y_res)

# Save and load model
joblib.dump(dtc, "credit_card_fraud_detection_model.pkl")
model = joblib.load("credit_card_fraud_detection_model.pkl")

# Example prediction
sample_transaction = [[-1.35980713, -0.07278117,  2.53634674,  1.37815522, -0.33832077,
                       0.46238778,  0.23959855,  0.0986979,  0.36378697,  0.09079417,
                       -0.55159953, -0.61780086, -0.99138985, -0.31116935,  1.46817697,
                       -0.47040053,  0.20797124,  0.02579058,  0.40399296,  0.2514121,
                       -0.01830678,  0.27783758, -0.11047391,  0.06692807,  0.12853936,
                       -0.18911484,  0.13355838, -0.02105305,  0.24496426]]
pred = model.predict(sample_transaction)

if pred[0] == 0:
    print("Normal Transaction")
else:
    print("Fraud Transaction")
